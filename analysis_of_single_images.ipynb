{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import scipy.ndimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder_functions import *\n",
    "from healing_mnist_functions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Import and Processing   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_rot = 0.5\n",
    "ratio_square = 0.5\n",
    "square_size = 5\n",
    "min = 3\n",
    "max = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HealingMNIST_rot_square(min=min, max=max, ratio_rot=ratio_rot, ratio_square=ratio_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = imageToTensor(data.train_images, data.train_labels, data.train_squares)\n",
    "test_dataset = imageToTensor(data.test_images, data.test_labels, data.test_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use dataloaders to efficiently store and retrieve the data\n",
    "batch_size=256\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder: set-up, training and evalulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the loss function\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "### Define an optimizer (both for the encoder and the decoder!)\n",
    "lr= 0.001\n",
    "\n",
    "### Set the random seed for reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "### Initialize the two networks\n",
    "d = 25\n",
    "\n",
    "### Define weight decay\n",
    "weight_decay = 0\n",
    "\n",
    "#model = Autoencoder(encoded_space_dim=encoded_space_dim)\n",
    "encoder = Encoder_original(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder_original(encoded_space_dim=d,fc2_input_dim=128)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "# Check if the GPU is available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f'Selected device: {device}')\n",
    "\n",
    "# Move both the encoder and the decoder to the selected device\n",
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_loss = evaluate_square(encoder, decoder, device, train_loader, loss_fn)\n",
    "print(initial_loss.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(encoder)\n",
    "print(decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "num_epochs = 25 #number of iterations\n",
    "diz_loss = {'train_loss':[],'val_loss':[]} #store training and evaluation loss\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss = train_square(encoder,decoder,device,\n",
    "   train_loader,loss_fn,optim) #train autoencoder on training set\n",
    "   val_loss = evaluate_square(encoder,decoder,device,test_loader,loss_fn) #evaluate perfomance of autoencoder on test set\n",
    "   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "   fig = plot_ae_outputs_square(test_dataset, device, encoder,decoder,n=10)\n",
    "   fig.show()\n",
    "   diz_loss['train_loss'].append(train_loss)\n",
    "   diz_loss['val_loss'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_img = plot_ae_outputs_square(encoder=encoder, decoder=decoder, test_dataset=test_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ae_outputs_square_custom(test_dataset= test_dataset, device=device, encoder=encoder, decoder=decoder, n=10, class_num=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-dimensional representation after training of convolutional autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How to get encoded samples\n",
    "#from network_functions import embedding\n",
    "enc_samples_train = embedding_with_square(train_dataset, device, encoder)\n",
    "enc_samples_test = embedding_with_square(test_dataset, device, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(enc_samples_test, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=enc_samples_test.label.astype(str), opacity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.io as pio\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_results = tsne.fit_transform(enc_samples_test.drop(['label', 'square'],axis=1))\n",
    "fig = px.scatter(tsne_results, x=0, y=1,\n",
    "                 color=enc_samples_test.label.astype(str),\n",
    "                 symbol=enc_samples_test.square.astype(str),\n",
    "                 symbol_sequence=['circle', 'cross'],\n",
    "                 labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier from low-dimensional embedding: set-up, training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_samples_train.drop(\"square\", axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = enc_samples_train.shape[0]\n",
    "n_test = enc_samples_test.shape[0]\n",
    "\n",
    "\n",
    "#print(n_train)\n",
    "\n",
    "enc_samples_train = np.array(enc_samples_train.astype(float))\n",
    "enc_samples_test = np.array(enc_samples_test.astype(float))\n",
    "\n",
    "enc_x_train = torch.Tensor(enc_samples_train[:,0:d]).to(torch.float).view(n_train,d)\n",
    "enc_y_train = torch.Tensor(enc_samples_train[:,d]).int().view(n_train,)\n",
    "\n",
    "enc_x_test = torch.Tensor(enc_samples_test[:,0:d]).to(torch.float).view(n_test,d)\n",
    "enc_y_test = torch.Tensor(enc_samples_test[:,d]).int().view(n_test,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "enc_train_dataset = TensorDataset(enc_x_train, enc_y_train)\n",
    "enc_test_dataset = TensorDataset(enc_x_test, enc_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "enc_train_loader = DataLoader(enc_train_dataset, batch_size=batch_size, shuffle=False)\n",
    "enc_test_loader = DataLoader(enc_test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_nn = MLP_Classifier(low_d=d)\n",
    "\n",
    "enc_loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "enc_optim = torch.optim.Adam(classifier_nn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=10\n",
    "for epoch in range(n):\n",
    "        classifier_nn.train()\n",
    "        train_loss = []\n",
    "        for batch_idx, (inputs, labels) in enumerate(enc_train_loader):\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "            enc_optim.zero_grad()\n",
    "\n",
    "            outputs = classifier_nn(inputs)\n",
    "            loss = enc_loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            enc_optim.step()\n",
    "            train_loss.append(loss.detach().cpu().numpy())\n",
    "\n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{n}], Batch [{batch_idx+1}/{len(enc_train_loader)}], Loss: {loss.item():.4f}' )\n",
    "        train_loss = np.mean(train_loss)\n",
    "        test_accuracy = evaluate_classifier(classifier_nn, enc_test_loader)\n",
    "        run.log({\"Classifier/train_loss\": train_loss, \"Classifier/accuracy\": test_accuracy}, step = epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = evaluate_classifier(classifier_nn, enc_test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_classifier_classwise(classifier_nn, enc_test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

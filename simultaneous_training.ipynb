{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "import random\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import wandb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoencoder_functions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-training autoencoder with classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input data formatting\n",
    "\n",
    "data_dir = 'dataset'\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(data_dir, train=True, download=True)\n",
    "test_dataset  = torchvision.datasets.MNIST(data_dir, train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset.transform = train_transform\n",
    "test_dataset.transform = test_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use dataloaders to efficiently store and retrieve the data\n",
    "batch_size=256\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definition of loss function\n",
    "loss_fn_reconstruction = torch.nn.MSELoss()\n",
    "loss_fn_classifier = torch.nn.CrossEntropyLoss()\n",
    "loss_p = 0.95\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## initalization of models\n",
    "d=25\n",
    "encoder = Encoder_original(encoded_space_dim=d,fc2_input_dim=128)\n",
    "decoder = Decoder_original(encoded_space_dim=d,fc2_input_dim=128)\n",
    "classifier = MLP_Classifier(low_d=d)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()},\n",
    "    {'params': classifier.parameters()}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## definition of optimizer\n",
    "lr = 0.01\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.to(device)\n",
    "decoder.to(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-Training of autoencoder and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10 #number of iterations\n",
    "diz_loss = {'train_loss':[],'val_loss':[]} #store training and evaluation loss\n",
    "for epoch in range(num_epochs):\n",
    "   train_loss, w_ae, w_cl = co_train(loss_p=loss_p, dataloader=train_loader, encoder=encoder, decoder=decoder, classifier=classifier,\n",
    "                         loss_fn_classifier=loss_fn_classifier, loss_fn_autoencoder=loss_fn_reconstruction, optimizer=optim, device=device) #train autoencoder on training set\n",
    "   val_loss_rec, val_loss_class, val_loss = co_evaluate(encoder=encoder, decoder=decoder, classifier=classifier, device=device, \n",
    "                                dataloader=test_loader, loss_fn_classifier=loss_fn_classifier, loss_fn_autoencoder=loss_fn_reconstruction, loss_p=loss_p) #evaluate perfomance of autoencoder on test set\n",
    "   print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'.format(epoch + 1, num_epochs,train_loss,val_loss))\n",
    "   fig = plot_ae_outputs(test_dataset, device, encoder,decoder,n=10)\n",
    "   fig.show()\n",
    "   diz_loss['train_loss'].append(train_loss)\n",
    "   diz_loss['val_loss'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = co_evaluate(encoder=encoder, decoder=decoder, classifier=classifier, device=device, \n",
    "                                dataloader=test_loader, loss_fn_classifier=loss_fn_classifier, loss_fn_autoencoder=loss_fn_reconstruction, loss_p=0.999)\n",
    "print(test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_img = plot_ae_outputs(encoder=encoder, decoder=decoder, test_dataset=test_dataset, device=device)\n",
    "rec_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_test = co_evaluate_classifier(classifier, test_loader, encoder)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_samples_train = embedding(train_dataset, device, encoder)\n",
    "enc_samples_test = embedding(test_dataset, device, encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "px.scatter(enc_samples_test, x='Enc. Variable 0', y='Enc. Variable 1', \n",
    "           color=enc_samples_test.label.astype(str), opacity=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import plotly.io as pio\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_results = tsne.fit_transform(enc_samples_test.drop(['label'],axis=1))\n",
    "fig = px.scatter(tsne_results, x=0, y=1,\n",
    "                 color=enc_samples_test.label.astype(str),\n",
    "                 labels={'0': 'tsne-2d-one', '1': 'tsne-2d-two'})\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_results = pca.fit_transform(enc_samples_test.drop(['label'],axis=1))\n",
    "fig = px.scatter(pca_results, x=0, y=1,\n",
    "                 color=enc_samples_test.label.astype(str),\n",
    "                 labels={'0': 'pca-2d-one', '1': 'pca-2d-two'})\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
